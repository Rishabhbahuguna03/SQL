{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3Yfo5TiFdgWyw640U3/Se",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishabhbahuguna03/SQL/blob/main/SQL_Split_Files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fOBj0jHR6xZ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b8cefca2-2a1c-49d9-b2dd-e2424268f132"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'yelp_academic_dataset_review.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3991653815.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Count total lines (objects) in the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtotal_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yelp_academic_dataset_review.json'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "input_file = \"yelp_academic_dataset_review.json\"  # Your 5GB JSON file\n",
        "output_prefix = \"split_file_\"  # Prefix for output files\n",
        "num_files = 20  # Number of files to split into\n",
        "\n",
        "# Count total lines (objects) in the file\n",
        "with open(input_file, \"r\" , encoding=\"utf8\") as f:\n",
        "    total_lines = sum(1 for _ in f)\n",
        "\n",
        "lines_per_file = total_lines // num_files  # Lines per split file\n",
        "\n",
        "print(f\"Total lines: {total_lines}, Lines per file: {lines_per_file}\")\n",
        "\n",
        "# Now split into multiple smaller files\n",
        "with open(input_file, \"r\" , encoding=\"utf8\") as f:\n",
        "    for i in range(num_files):\n",
        "        output_filename = f\"{output_prefix}{i+1}.json\"\n",
        "\n",
        "        with open(output_filename, \"w\", encoding=\"utf8\" ) as out_file:\n",
        "            for j in range(lines_per_file):\n",
        "                line = f.readline()\n",
        "                if not line:\n",
        "                    break  # Stop if file ends early\n",
        "                out_file.write(line)\n",
        "\n",
        "print(\"âœ… JSON file successfully split into smaller parts!\")"
      ]
    }
  ]
}